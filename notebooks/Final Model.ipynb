{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Nick/Desktop/proj_cs109/Data\n"
     ]
    }
   ],
   "source": [
    "cd ~/Desktop/proj_cs109/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy.random import randint\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import OrderedDict\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from my_functions import for_loop_status\n",
    "from my_functions import for_loop_status2\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.patches as mpatches\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "import sys as sys\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.481865%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nick/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Nick/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random class. accuracy, train:  0.305882352941\n",
      "Random class. accuracy, test:  0.373684210526\n",
      "All zeros class. accuracy, train:  0.411764705882\n",
      "All zeros class. accuracy, test:  0.415789473684\n",
      "All ones class. accuracy, train:  0.4\n",
      "All ones class. accuracy, test:  0.421052631579\n",
      "All twos class. accuracy, train:  0.188235294118\n",
      "All twos class. accuracy, test:  0.163157894737\n",
      "Gradient Boost with PCA and CV class. accuracy, train:  0.888235294118\n",
      "Gradient Boost with PCA and CV class. accuracy, test:  0.421052631579\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "gene_corr_base = pd.read_csv('gene_corr_base.csv', index_col = None, header=None)\n",
    "gene_corr_cut = pd.read_csv('gene_corr_cut.csv', index_col = None, header=None)\n",
    "gene_corr_p = pd.read_csv('gene_corr_p.csv', index_col = None, header=None)\n",
    "gene_names = pd.read_csv('gene_names.csv', index_col = None, header=None)\n",
    "df_full = pd.read_csv('post_imputation.csv', index_col = 0)\n",
    "\n",
    "# just gene expression data\n",
    "X_full = df_full.iloc[:,14:49400]\n",
    "\n",
    "# make correlations dataframe\n",
    "corrs_df = pd.DataFrame()\n",
    "corrs_df['Gene_Name'] = gene_names[0]\n",
    "corrs_df['Base'] = gene_corr_base[0]/15\n",
    "corrs_df['Cut'] = gene_corr_cut[0]/15\n",
    "corrs_df['p'] = gene_corr_p[0]/15\n",
    "\n",
    "# choose most significant genes\n",
    "Used = corrs_df[corrs_df.p < 0.01]\n",
    "used_genes = list(Used.Gene_Name.values)\n",
    "\n",
    "# interaction and polynomial terms\n",
    "predictors_expo_list = []\n",
    "for_index = 0\n",
    "index = 0\n",
    "for predictor in used_genes:\n",
    "    for_index = for_loop_status(len(used_genes), for_index)\n",
    "    predictors_temp_list = []\n",
    "    for expo in [2,3,4]:\n",
    "        #if expo = 2 and the predictor is atemp\n",
    "        #then you'll get \"atemp2\" which is atemp^2\n",
    "        predictors_temp_list.append('{0}{1}'.format(predictor, expo))\n",
    "        df_full['{0}{1}'.format(predictor, expo)] = df_full['{0}'.format(predictor)]**int('{0}'.format(expo))\n",
    "    predictors_expo_list.append(predictors_temp_list)\n",
    "    for predictor2 in used_genes[int(index + 1):]:\n",
    "        if predictor != predictor2:\n",
    "            df_full['{0}_x_{1}'.format(predictor, predictor2)] = df_full['{0}'.format(predictor)] * df_full['{0}'.format(predictor2)]\n",
    "            #for predictor3 in predictors[int(index + 2):]:\n",
    "             #   if predictor2 != predictor3:\n",
    "              #      df_full['{0}_x_{1}_x_{2}'.format(predictor, predictor2, predictor3)] = df_full['{0}'.format(predictor)] * df_full['{0}'.format(predictor2)] * df_full['{0}'.format(predictor3)]\n",
    "    index += 1\n",
    "\n",
    "# output processed data\n",
    "df_full.to_csv('poly_interactions.csv')\n",
    "df_full.dtypes.to_csv('poly_interactions_columntypes.txt')\n",
    "\n",
    "# find index of first polynomial term\n",
    "firstpoly = df_full.columns.get_loc('DX_Final_Rate') + 1\n",
    "\n",
    "# remove rows where diagnosis changes\n",
    "df_full_removed = df_full[df_full['DX_Final_Progression'] != 0]\n",
    "df_full_removed.to_csv('df_full_removed.csv')\n",
    "df_full = df_full[df_full['DX_Final_Progression'] == 0]\n",
    "\n",
    "#original genes and new poly/interaction terms\n",
    "temp_genes = used_genes.copy()\n",
    "full_genes = temp_genes + list(df_full.columns[firstpoly:].values)\n",
    "X_full = df_full[full_genes]\n",
    "y_full = df_full['DX']\n",
    "X_full_removed = df_full_removed[full_genes]\n",
    "y_full_removed = df_full_removed['DX']\n",
    "X_full_removed.to_csv('X_full_removed.csv')\n",
    "y_full_removed.to_csv('y_full_removed.csv')\n",
    "\n",
    "# split into train and test\n",
    "np.random.seed(9001)\n",
    "msk = np.random.rand(len(X_full)) < 0.5\n",
    "X_train = X_full[msk]\n",
    "X_test = X_full[~msk]\n",
    "y_train = y_full[msk]\n",
    "y_test = y_full[~msk]\n",
    "\n",
    "# making classifiers to test our model against\n",
    "# random classifier\n",
    "yrand_train = randint(3, size = len(X_train))\n",
    "yrand_test = randint(3, size = len(X_test))\n",
    "# all zeros classifier\n",
    "zeros = {}\n",
    "zeros['train_pred'] = [0] * len(X_train)\n",
    "zeros['test_pred'] = [0] * len(X_test)\n",
    "zeros['model'] = np.zeros(len(X_test))\n",
    "# all ones classifier\n",
    "ones = {}\n",
    "ones['train_pred'] = [1] * len(X_train)\n",
    "ones['test_pred'] = [1] * len(X_test)\n",
    "ones['model'] = np.ones(len(X_test))\n",
    "\n",
    "# all twos classifier\n",
    "twos = {}\n",
    "twos['train_pred'] = [2] * len(X_train)\n",
    "twos['test_pred'] = [2] * len(X_test)\n",
    "twos['model'] = np.ones(len(X_test))*2\n",
    "\n",
    "pre_X_train = X_train\n",
    "pre_X_test = X_test\n",
    "pre_X_train['class'] = y_train\n",
    "pre_X_test['class'] = y_test\n",
    "\n",
    "# PCA with all components\n",
    "pca_full_fit = PCA()\n",
    "pca_full = {}\n",
    "pca_full['Xtrain'] = pca_full_fit.fit_transform(pre_X_train)\n",
    "\n",
    "# find number of components that explain 90% of predictor variance\n",
    "n_components = (np.argwhere((np.cumsum(pca_full_fit.explained_variance_ratio_)) > 0.9)[0] + 1)[0]\n",
    "\n",
    "# PCA with 90% of variance explained\n",
    "pca90 = {}\n",
    "pca90_fit = PCA(n_components, random_state = 9001)\n",
    "pca90_fit.fit(pre_X_train)\n",
    "X_train = pca90_fit.transform(pre_X_train)\n",
    "X_test = pca90_fit.transform(pre_X_test)\n",
    "\n",
    "# run cv on multiple parameters in gradient boosting\n",
    "param_dict = OrderedDict(\n",
    "    max_depth = range(1,20),\n",
    "    n_estimators = range(1,20),\n",
    "    learning_rate = np.arange(0.05,1,0.05)\n",
    ")\n",
    "est = GradientBoostingClassifier(random_state = 9001)\n",
    "gb_cv = GridSearchCV(est, param_grid = param_dict, cv=3, n_jobs=-1)\n",
    "gb_cv.fit(X_train, y_train)\n",
    "opt_depth = gb_cv.best_estimator_.max_depth\n",
    "opt_n_est = gb_cv.best_estimator_.n_estimators\n",
    "opt_lr = gb_cv.best_estimator_.learning_rate\n",
    "\n",
    "# output accuracy for our new method, and comparison to benchmark models\n",
    "print('Random class. accuracy, train: ', accuracy_score(y_train, yrand_train))\n",
    "print('Random class. accuracy, test: ', accuracy_score(y_test, yrand_test))\n",
    "print('All zeros class. accuracy, train: ', accuracy_score(y_train, zeros['train_pred']))\n",
    "print('All zeros class. accuracy, test: ', accuracy_score(y_test, zeros['test_pred']))\n",
    "print('All ones class. accuracy, train: ', accuracy_score(y_train, ones['train_pred']))\n",
    "print('All ones class. accuracy, test: ', accuracy_score(y_test, ones['test_pred']))\n",
    "print('All twos class. accuracy, train: ', accuracy_score(y_train, twos['train_pred']))\n",
    "print('All twos class. accuracy, test: ', accuracy_score(y_test, twos['test_pred']))\n",
    "print('Gradient Boost with PCA and CV class. accuracy, train: ', metrics.accuracy_score(y_train, gb_cv.best_estimator_.fit(X_train, y_train).predict(X_train)))\n",
    "print('Gradient Boost with PCA and CV class. accuracy, test: ', metrics.accuracy_score(y_test, gb_cv.best_estimator_.fit(X_train, y_train).predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.linspace(0.53333333, 0.66666667, 7)\n",
    "np.random.seed(9001)\n",
    "df = pd.read_csv('poly_interactions.csv', index_col = 0, dtype = {'DX': np.int32})\n",
    "cols = df.dtypes\n",
    "cols.to_csv('columntypes.txt')\n",
    "df['DX'] = df['DX'] + 1\n",
    "firstgene = df.columns.get_loc('DX') + 1\n",
    "middle_start = df.columns.get_loc('SubjectID') - 1\n",
    "end_start = df.columns.get_loc('DX_Final_Rate') + 1\n",
    "df_start = df.iloc[:,firstgene:(middle_start+1)]\n",
    "df_end = df.iloc[:,end_start:]\n",
    "df = pd.concat([df_start, df_end, df.DX], axis = 1)\n",
    "msk = np.random.rand(len(df)) < 0.5\n",
    "data_train = df[msk]\n",
    "data_test = df[~msk]\n",
    "data = {}\n",
    "models = {}\n",
    "data['alz'] = {'xtrain' : data_train.drop('DX', axis = 1).values,\n",
    "               'ytrain' : data_train['DX'].values,\n",
    "               'xtest' : data_test.drop('DX', axis = 1).values,\n",
    "               'ytest' : data_test['DX'].values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define classifiction accuracy formula\n",
    "def class_acc(y, y_pred):\n",
    "    mis = 0\n",
    "    length = len(y_pred)\n",
    "    for prediction in range(0,len(y)):\n",
    "        if y_pred[prediction] == 0:\n",
    "            length -= 1\n",
    "        elif y[prediction] != y_pred[prediction]:\n",
    "            mis += 1\n",
    "    score = (1 - mis/len(y_pred)) #calculate 1 - misclassification rate\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "calc_cost\n",
    "\n",
    "Inputs\n",
    "------\n",
    "y = the true class\n",
    "y_pred = the predicted class (or abstain)\n",
    "ab_cost = the cost of abstaining\n",
    "mis_cost = the cost of a misclassification\n",
    "ab_class = what class is abstain?\n",
    "\n",
    "Returns\n",
    "-------\n",
    "the cost of this model on the test data per patient\n",
    "note that a misclassification = 5000\n",
    "and an abstain (3) = 1000\n",
    "\n",
    "\"\"\"\n",
    "def calc_cost(y, y_pred, ab_cost = 6850, mis_cost = 12000, ab_class = 0):\n",
    "    mis = 0\n",
    "    ab = 0\n",
    "    for prediction in range(0,len(y)):\n",
    "        if y[prediction] != y_pred[prediction] and y_pred[prediction] != ab_class:\n",
    "            mis += 1\n",
    "        if y_pred[prediction] == ab_class:\n",
    "            ab += 1\n",
    "    return ((ab * ab_cost + mis * mis_cost)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "abstain\n",
    "\n",
    "Inputs\n",
    "------\n",
    "preds = a list of the the predictions\n",
    "probs = a list of the probability for each prediciton\n",
    "mci_thresh = the threshold for mci\n",
    "dementia_thresh = the threshold for dementia\n",
    "cn_thresh = the threshold for cn\n",
    "\n",
    "Returns\n",
    "-------\n",
    "ab_pred = the predictions with abstains\n",
    "\n",
    "\"\"\"\n",
    "def abstain(preds, probs, mci_thresh = 0, dementia_thresh = 0, cn_thresh = 0):\n",
    "    cog_norm = 1\n",
    "    mci = 2\n",
    "    dementia = 3\n",
    "    ab = 0\n",
    "    \n",
    "    ab_pred = []\n",
    "    \n",
    "    for i in range(0,len(preds)):\n",
    "        if preds[i] == cog_norm and probs[i] < cn_thresh or preds[i] == mci and probs[i] < mci_thresh or preds[i] == dementia and probs[i] < dementia_thresh:\n",
    "            ab_pred.append(ab) #abstain if the probability isn't high enough\n",
    "        else:\n",
    "            ab_pred.append(preds[i]) #accept the original probability\n",
    "    \n",
    "    return ab_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "ab_model\n",
    "\n",
    "Inputs\n",
    "------\n",
    "name = the name to use for the model\n",
    "data_ = a dictionary of the data to use to train and test\n",
    "    which should contain 'xtest' 'xtrain' 'ytest' and 'ytrain'\n",
    "    if using with a validation set, make sure the data\n",
    "    passed in is still labelled as 'xtest' and 'ytest'\n",
    "    (i.e. not 'xvalid' and 'yvalid')\n",
    "mci_thresh = the threshold for abstaining from mci\n",
    "    a lower threshold = less abstaining\n",
    "dementia_thresh = threshold for abstaining from dementia\n",
    "cn_thresh = threshold for abstaining from cog_normal\n",
    "\n",
    "Returns\n",
    "-------\n",
    "a dictionary containing this model's\n",
    "(1) mci, dementia, and cog_normal thresholds\n",
    "(2) the cost of this model\n",
    "(3) the acc of this model (for those on which it does not abstain)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def ab_model_original(name, data_, mci_thresh = 0, dementia_thresh = 0, cn_thresh = 0): \n",
    "    bm = gb_cv.best_estimator_\n",
    "    models[name] = bm\n",
    "    models[name].fit(data[name]['xtrain'], data[name]['ytrain'])\n",
    "\n",
    "    y_pred = models[name].predict(data[name]['xtest'])\n",
    "    y_probs = models[name].predict_proba(data[name]['xtest'])\n",
    "    y_prob = []\n",
    "    \n",
    "    for i in range(0,len(y_pred)):\n",
    "        y_prob.append(y_probs[i][y_pred[i] - 1])\n",
    "    \n",
    "    y_ab = abstain(y_pred, y_prob, mci_thresh = mci_thresh, dementia_thresh = dementia_thresh, cn_thresh = cn_thresh)\n",
    "    ab_percent = (np.count_nonzero(y_ab))/len(y_ab)\n",
    "    \n",
    "    cost = calc_cost(data[name]['ytest'], y_ab)\n",
    "    acc = class_acc(data[name]['ytest'], y_ab)\n",
    "    \n",
    "    ab_models[name] = {'model' : models[name],\n",
    "                       'mci_thresh' : mci_thresh,\n",
    "                       'dementia_thresh' : dementia_thresh,\n",
    "                       'cn_thresh' : cn_thresh,\n",
    "                       'raw predictions' : y_pred,\n",
    "                       'predictions' : y_ab,\n",
    "                       'probabilities' : y_prob,\n",
    "                       'cost' : cost,\n",
    "                       'acc' : acc,\n",
    "                       'percent' : ab_percent,\n",
    "                      }\n",
    "    \n",
    "    return ab_models[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "ab_model\n",
    "\n",
    "Inputs\n",
    "------\n",
    "name = the name to use for the model\n",
    "data_ = a dictionary of the data to use to train and test\n",
    "    which should contain 'xtest' 'xtrain' 'ytest' and 'ytrain'\n",
    "    if using with a validation set, make sure the data\n",
    "    passed in is still labelled as 'xtest' and 'ytest'\n",
    "    (i.e. not 'xvalid' and 'yvalid')\n",
    "mci_thresh = the threshold for abstaining from mci\n",
    "    a lower threshold = less abstaining\n",
    "dementia_thresh = threshold for abstaining from dementia\n",
    "cn_thresh = threshold for abstaining from cog_normal\n",
    "\n",
    "Returns\n",
    "-------\n",
    "a dictionary containing this model's\n",
    "(1) mci, dementia, and cog_normal thresholds\n",
    "(2) the cost of this model\n",
    "(3) the acc of this model (for those on which it does not abstain)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def ab_model(name, y_pred, y_prob, mci_thresh, dementia_thresh, cn_thresh): \n",
    "    bm = gb_cv.best_estimator_\n",
    "    models[name] = bm\n",
    "    \n",
    "    y_ab = abstain(y_pred, y_prob, mci_thresh = mci_thresh, dementia_thresh = dementia_thresh, cn_thresh = cn_thresh)\n",
    "    ab_percent = (np.count_nonzero(y_ab))/len(y_ab)\n",
    "    \n",
    "    cost = calc_cost(data[name]['ytest'], y_ab)\n",
    "    acc = class_acc(data[name]['ytest'], y_ab)\n",
    "    \n",
    "    ab_model_dict = {'model' : models[name],\n",
    "                       'mci_thresh' : mci_thresh,\n",
    "                       'dementia_thresh' : dementia_thresh,\n",
    "                       'cn_thresh' : cn_thresh,\n",
    "                       'raw predictions' : y_pred,\n",
    "                       'predictions' : y_ab,\n",
    "                       'probabilities' : y_prob,\n",
    "                       'cost' : cost,\n",
    "                       'acc' : acc,\n",
    "                       'percent' : ab_percent,\n",
    "                      }\n",
    "    \n",
    "    return ab_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.000000%"
     ]
    }
   ],
   "source": [
    "#now we're going to actually fine-tune the threshold values\n",
    "#using reasonable estimates from the above examination\n",
    "#of the data\n",
    "#note that this can be used to find threshold values for\n",
    "#literally any combination of abstain costs and misclassification costs\n",
    "#since you would simply need to adjust the cost in the function\n",
    "#calc_cost above as that is used for the accuracy\n",
    "\n",
    "#define lists to use for the different thresholds checks to get a model that Werks\n",
    "iteration_max = 5\n",
    "models = {}\n",
    "\n",
    "#get best model\n",
    "bm = gb_cv.best_estimator_\n",
    "\n",
    "index = 0\n",
    "n_models = 5\n",
    "fold = 0\n",
    "ab_models = []\n",
    "\n",
    "#first make all of the models\n",
    "#splits the training and valid\n",
    "#note that it does the same every time\n",
    "for train, valid in KFold(n_models, shuffle = True, random_state = 9001).split(data_train):\n",
    "    #prepare the train and valid data\n",
    "    fold_name = 'fold {0}'.format(fold) #name of the model\n",
    "    fold += 1\n",
    "    data[fold_name] = {'xtrain' : data_train.drop('DX', axis = 1).iloc[train].values,\n",
    "                                  'xtest' : data_train.drop('DX', axis = 1).iloc[valid].values,\n",
    "                                  'ytrain' : data_train['DX'].iloc[train].values,\n",
    "                                  'ytest' : data_train['DX'].iloc[valid].values,\n",
    "                      }\n",
    "    #make and fit the model\n",
    "    models[fold_name] = bm \n",
    "    models[fold_name].fit(data[fold_name]['xtrain'], data[fold_name]['ytrain'])\n",
    "    #predict and get probabilities\n",
    "    y_pred = models[fold_name].predict(data[fold_name]['xtest'])\n",
    "    y_probs = models[fold_name].predict_proba(data[fold_name]['xtest'])\n",
    "    \n",
    "    #get the probabilities corresponding to the class of each prediction\n",
    "    #i.e. if the first prediction is \"1\", then get the probability of prediction of class \"1\",\n",
    "    #discarding \"0\" and \"2\" for the first prediction\n",
    "    #since the original probabilities are stored in a matrix\n",
    "    y_prob = []\n",
    "    for i in range(0,len(y_pred)):\n",
    "        y_prob.append(y_probs[i][y_pred[i] - 1])\n",
    "    \n",
    "    temp_model = {'model' : models[fold_name],\n",
    "                  'name' : fold_name,\n",
    "                  'predictions' : y_pred,\n",
    "                  'probabilities' : y_prob,\n",
    "                 }\n",
    "    \n",
    "    ab_models.append(temp_model)\n",
    "    index = for_loop_status(n_models, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\t\tmci\tdem\tcn\tcost\tacc\tpercent\n",
      "19.984974%\t0.7000\t1.0000\t1.0000\t6173.51\t0.8502\t0.3612\n",
      "39.984974%\t0.7400\t1.0000\t0.9800\t6133.70\t0.8642\t0.3424\n",
      "59.984974%\t0.7320\t0.9968\t0.9800\t6133.70\t0.8642\t0.3424\n",
      "79.984974%\t0.7312\t0.9958\t0.9784\t6133.70\t0.8642\t0.3424\n",
      "99.984974%\t0.7312\t0.9958\t0.9781\t6133.70\t0.8642\t0.3424\n"
     ]
    }
   ],
   "source": [
    "#now we will use the above fitted models for the threshold!\n",
    "start_cn = 0\n",
    "stop_cn = 1\n",
    "start_mci = 0\n",
    "stop_mci = 1\n",
    "start_dementia = 0.6\n",
    "stop_dementia = 1\n",
    "n_thresh = 11\n",
    "cn_thresholds = list(np.linspace(start_cn, stop_cn, n_thresh))\n",
    "mci_thresholds = list(np.linspace(start_mci, stop_mci, n_thresh))\n",
    "dementia_thresholds = list(np.linspace(start_dementia, stop_dementia, n_thresh))\n",
    "index = 0\n",
    "print('done!\\t\\tmci\\tdem\\tcn\\tcost\\tacc\\tpercent')\n",
    "length = length = len(cn_thresholds) * len(mci_thresholds) * len(dementia_thresholds) * (iteration_max)\n",
    "for iteration in range(1,iteration_max + 1):\n",
    "    \n",
    "    thresh_models = {} #prepare dictionary to hold the separate models\n",
    "\n",
    "    #iterates through every single possibility\n",
    "    for cn_thresh in cn_thresholds:\n",
    "        for mci_thresh in mci_thresholds:\n",
    "            for dementia_thresh in dementia_thresholds:\n",
    "                temp_costs = []\n",
    "                temp_accs = []\n",
    "                temp_percents = []\n",
    "                thresh_name = 'threshold set {}'.format(index) \n",
    "                for ab_cv_model in ab_models:\n",
    "                    temp_thresh_model = (ab_model(ab_cv_model['name'], ab_cv_model['predictions'], ab_cv_model['probabilities'], mci_thresh = mci_thresh, dementia_thresh = dementia_thresh, cn_thresh = cn_thresh)) #get the model\n",
    "                    temp_costs.append(temp_thresh_model['cost']) #get the cost\n",
    "                    temp_accs.append(temp_thresh_model['acc']) #get the acc\n",
    "                    temp_percents.append(temp_thresh_model['percent']) #get abstainp ercent\n",
    "                avg_cost = sum(temp_costs)/len(temp_costs) #average the costs\n",
    "                avg_acc = sum(temp_accs)/len(temp_accs) #average the accs\n",
    "                avg_percent = sum(temp_percents)/len(temp_percents) #get percent abstained\n",
    "                \n",
    "                #make an entry\n",
    "                thresh_models[thresh_name] = {'mci_thresh' : mci_thresh,\n",
    "                                              'dementia_thresh' : dementia_thresh,\n",
    "                                              'cn_thresh' : cn_thresh,\n",
    "                                              'cost' : avg_cost,\n",
    "                                              'acc' : avg_acc,\n",
    "                                              'percent' : avg_percent,\n",
    "                                             }\n",
    "                index = for_loop_status(length, index)\n",
    "                \n",
    "    #find the model with the minimum cost\n",
    "    #and store the name of that model in min_name\n",
    "    min_cost = 100000000 #arbitrarily high value\n",
    "    min_name = ''\n",
    "\n",
    "    for key, model in thresh_models.items():\n",
    "        if min_cost > model['cost']: #if it's lower than the current minimum\n",
    "            min_cost = model['cost']\n",
    "            min_name = key\n",
    "\n",
    "    print('\\t{0:.4f}\\t{1:.4f}\\t{2:.4f}\\t{3:.2f}\\t{4:.4f}\\t{5:.4f}'.format(thresh_models[min_name]['mci_thresh'],\n",
    "                                                                                  thresh_models[min_name]['dementia_thresh'],\n",
    "                                                                                 thresh_models[min_name]['cn_thresh'],\n",
    "                                                                                 thresh_models[min_name]['cost'],\n",
    "                                                                                 thresh_models[min_name]['acc'],\n",
    "                                                                                 thresh_models[min_name]['percent']))\n",
    "    #create thresholds based on cost-minimizing model\n",
    "    thresh_min_dementia = thresh_models[min_name]['dementia_thresh']\n",
    "    thresh_min_mci = thresh_models[min_name]['mci_thresh']\n",
    "    thresh_min_cn = thresh_models[min_name]['cn_thresh']\n",
    "    cn_thresh_index = cn_thresholds.index(thresh_min_cn)\n",
    "    mci_thresh_index = mci_thresholds.index(thresh_min_mci)\n",
    "    dementia_thresh_index = dementia_thresholds.index(thresh_min_dementia)\n",
    "    \n",
    "    #prevent thresholds from going above 1 or below 0\n",
    "    if cn_thresholds.index(thresh_min_cn) == 0:\n",
    "        cn_thresh_index = 1\n",
    "    elif cn_thresholds.index(thresh_min_cn) == (len(cn_thresholds) - 1):\n",
    "        cn_thresh_index = len(cn_thresholds) - 2\n",
    "    if mci_thresholds.index(thresh_min_mci) == 0:\n",
    "        mci_thresh_index = 1\n",
    "    elif mci_thresholds.index(thresh_min_mci) == (len(mci_thresholds) - 1):\n",
    "        mci_thresh_index = len(mci_thresholds) - 2\n",
    "    if dementia_thresholds.index(thresh_min_dementia) == 0:\n",
    "        dementia_thresh_index = 1\n",
    "    elif dementia_thresholds.index(thresh_min_dementia) == (len(dementia_thresholds) - 1):\n",
    "        dementia_thresh_index = len(dementia_thresholds) - 2\n",
    "        \n",
    "    #change thresholds to be one decimal point more\n",
    "    start_cn = cn_thresholds[cn_thresh_index - 1]\n",
    "    stop_cn = cn_thresholds[cn_thresh_index + 1]\n",
    "    start_mci = mci_thresholds[mci_thresh_index - 1]\n",
    "    stop_mci = mci_thresholds[mci_thresh_index + 1]\n",
    "    start_dementia = dementia_thresholds[dementia_thresh_index - 1]\n",
    "    stop_dementia = dementia_thresholds[dementia_thresh_index + 1]\n",
    "    \n",
    "    #create new thresholds    \n",
    "    cn_thresholds = list(np.linspace(start_cn, stop_cn, n_thresh))\n",
    "    mci_thresholds = list(np.linspace(start_mci, stop_mci, n_thresh))\n",
    "    dementia_thresholds = list(np.linspace(start_dementia, stop_dementia, n_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost per patient for the model set with thresholds is: $6776.32 and classification accuracy is 0.89 and % diagnosed is 0.21.\n"
     ]
    }
   ],
   "source": [
    "#make the final model using the threshold values above\n",
    "#and find its cost\n",
    "name = 'final model'\n",
    "models[name] = bm \n",
    "data[name] = data['alz']\n",
    "models[name].fit(data['alz']['xtrain'], data['alz']['ytrain'])\n",
    "y_pred = models[name].predict(data['alz']['xtest'])\n",
    "y_probs = models[name].predict_proba(data['alz']['xtest'])\n",
    "    \n",
    "#get the probabilities corresponding to the class of each prediction\n",
    "#i.e. if the first prediction is \"1\", then get the probability of prediction of class \"1\",\n",
    "#discarding \"0\" and \"2\" for the first prediction\n",
    "#since the original probabilities are stored in a matrix\n",
    "y_prob = []\n",
    "for i in range(0,len(y_pred)):\n",
    "    y_prob.append(y_probs[i][y_pred[i] - 1])\n",
    "final_model = ab_model(name, y_pred, y_prob, thresh_models[min_name]['mci_thresh'], thresh_models[min_name]['dementia_thresh'], thresh_models[min_name]['cn_thresh'])\n",
    "print('The cost per patient for the model set with thresholds is: ${0:.2f} and classification accuracy is {1:.2f} and % diagnosed is {2:.2f}.'.format(final_model['cost'], final_model['acc'], final_model['percent']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
