{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Nick/Desktop/proj_cs109/Data\n"
     ]
    }
   ],
   "source": [
    "cd ~/Desktop/proj_cs109/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from numpy.random import randint\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define classifiction accuracy formula\n",
    "def class_ac(y, y_pred):\n",
    "    mis = 0\n",
    "    for prediction in range(0,len(y)):\n",
    "        if y[prediction] != y_pred[prediction]:\n",
    "            mis += 1\n",
    "    score = (1 - mis/len(y_pred)) #calculate 1 - misclassification rate\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load dataset\n",
    "df_full = pd.read_csv('FINAL_GENE_EXPRESSION.csv', index_col = 0)\n",
    "\n",
    "#drop columns with high missingness\n",
    "df_full = df_full.drop(['EcogPtMem', 'EcogPtLang', 'EcogPtVisspat', 'EcogPtPlan', 'EcogPtOrgan', 'EcogPtDivatt', 'EcogPtTotal', 'RAVLT_forgetting'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#locate rows with missing values (found earlier)\n",
    "missing_rows = df_full.apply(lambda x: 49431-x.count(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop rows with DX missing\n",
    "df_full = df_full.dropna(subset = ['DX'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get names of missing columns in each row\n",
    "lst = []\n",
    "for index, row in df_full.iterrows():\n",
    "    mask = row.isnull()\n",
    "    lst += [row[mask].index.tolist()]\n",
    "missing_list = []\n",
    "for listy in lst:\n",
    "    if len(listy) != 0:\n",
    "        missing_list.append(listy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate number of missing values in each row\n",
    "missing_rows = df_full.isnull().sum(axis=1)\n",
    "missing_r = pd.DataFrame(missing_rows, columns = ['Count'])\n",
    "missing_r = missing_r[missing_r['Count'] > 0]\n",
    "missing_r['Missing_vals'] = missing_list\n",
    "missing_r = missing_r[missing_r['Count'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set alpha values\n",
    "alphas = np.zeros(11)\n",
    "for i in np.arange(-5,6,1):\n",
    "    alphas[i] = 10.0** i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ADAS11', 'ADAS13', 'RAVLT_immediate', 'RAVLT_learning',\n",
      "       'RAVLT_perc_forgetting', 'FAQ', 'MOCA', 'EcogSPMem', 'EcogSPLang',\n",
      "       'EcogSPVisspat', 'EcogSPPlan', 'EcogSPOrgan', 'EcogSPDivatt',\n",
      "       'EcogSPTotal'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(441, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imputation through a model\n",
    "#adapted from lab7\n",
    "df_miss = pd.read_csv('FINAL_GENE_EXPRESSION.csv', index_col = 0)\n",
    "df_miss = df_miss[['CDRSB', 'ADAS11', 'ADAS13',\n",
    "       'MMSE', 'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_perc_forgetting',\n",
    "       'FAQ', 'MOCA', 'EcogSPMem', 'EcogSPLang', 'EcogSPVisspat', 'EcogSPPlan',\n",
    "       'EcogSPOrgan', 'EcogSPDivatt', 'EcogSPTotal', 'DX']]\n",
    "df_miss_cut = df_miss.dropna(how='all')\n",
    "df_filled = df_miss.copy()\n",
    "#using the intact data\n",
    "#build a model to use to impute\n",
    "#onto the dataset that has missing values\n",
    "#for each given predictors\n",
    "df_miss_cut = df_miss_cut.drop('DX', axis =1 )\n",
    "null_predictors = df_miss_cut.columns[df_miss_cut.isnull().any()] #get null predictors\n",
    "print(null_predictors)\n",
    "df_miss_cut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now working on ADAS11.\n",
      "The r2 score is 0.6832152845413335.\n",
      "Now working on ADAS13.\n",
      "The r2 score is 0.6822339396037445.\n",
      "Now working on RAVLT_immediate.\n",
      "The r2 score is 0.39138497985134724.\n",
      "Now working on RAVLT_learning.\n",
      "The r2 score is 0.2021633388767654.\n",
      "Now working on RAVLT_perc_forgetting.\n",
      "The r2 score is 0.2684739057011736.\n",
      "Now working on FAQ.\n",
      "The r2 score is 0.7531252677282848.\n",
      "Now working on MOCA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nick/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1082: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/Nick/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1082: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/Nick/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1082: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/Nick/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1082: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/Nick/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1082: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/Nick/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1082: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 score is 0.5850571375652185.\n",
      "Now working on EcogSPMem.\n",
      "The r2 score is 0.5300661421776194.\n",
      "Now working on EcogSPLang.\n",
      "The r2 score is 0.48388589143871863.\n",
      "Now working on EcogSPVisspat.\n",
      "The r2 score is 0.5554280667685116.\n",
      "Now working on EcogSPPlan.\n",
      "The r2 score is 0.5508304299920903.\n",
      "Now working on EcogSPOrgan.\n",
      "The r2 score is 0.5145290923953789.\n",
      "Now working on EcogSPDivatt.\n",
      "The r2 score is 0.4639033601271356.\n",
      "Now working on EcogSPTotal.\n",
      "The r2 score is 0.6189780074542853.\n",
      "Index([], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nick/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1082: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/Nick/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1082: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/Nick/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1082: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/Nick/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1082: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/Nick/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1082: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/Nick/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1082: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/Nick/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1082: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/Nick/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1082: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#imputation using LASSO\n",
    "#define model dict\n",
    "model = {}\n",
    "\n",
    "#impute\n",
    "for predictor in null_predictors:\n",
    "    print('Now working on {}.'.format(predictor))\n",
    "    #first the missing values\n",
    "    #from the dataset\n",
    "    null_miss = df_miss_cut[pd.DataFrame(data = df_miss_cut[predictor], index = df_miss_cut.index).isnull().any(axis=1)] #get all rows with missing values in that predict\n",
    "    #and the missing index from earlier\n",
    "    xmiss = null_miss.drop(null_predictors, axis=1)\n",
    "    miss_index = df_miss_cut[predictor][df_miss_cut[predictor].isnull()].index #index of missing rows\n",
    "    #now use the intact database\n",
    "    #to create the model\n",
    "    xnomiss = df_miss_cut.drop(null_predictors, axis=1)\n",
    "    ynomiss = pd.DataFrame(data = df_miss_cut[predictor], index = df_miss_cut[predictor].index) #note that ynomiss is looking at that particular predictor, not \"is_cancer\n",
    "    xnomiss = xnomiss.drop(miss_index)\n",
    "    ynomiss = ynomiss.drop(miss_index)\n",
    "    #create the model\n",
    "    model['Lasso'] = LassoCV(alphas = alphas) #linear regression\n",
    "    model['Lasso'].fit(xnomiss, ynomiss) #fit\n",
    "    ynomiss_pred = model['Lasso'].predict(xnomiss) #predict on not-missing data\n",
    "    print('The r2 score is {}.'.format(r2_score(ynomiss.values, ynomiss_pred)))\n",
    "    ymiss_pred = model['Lasso'].predict(xmiss) #predict on missing data\n",
    "    #now include noise in the model\n",
    "    #using mean squared error\n",
    "    #calculated by the not-missing data\n",
    "    #so we know how generally accurate\n",
    "    #the model is and can thus\n",
    "    #add appropriate noise\n",
    "    ymiss_pred_noisy = ymiss_pred + np.random.normal(loc = 0, scale = np.sqrt(mean_squared_error(ynomiss.values, ynomiss_pred)), size = ymiss_pred.shape)\n",
    "    #put together the imputed values\n",
    "    miss_series = pd.Series(data = ymiss_pred.flatten(), index = miss_index)\n",
    "    df_filled[predictor] = df_filled[predictor].fillna(miss_series)\n",
    "null_predictors_check = df_filled.columns[df_filled.isnull().any()] #get null predictors\n",
    "print(null_predictors_check) #check to make sure this is empty!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now do the split and do the logistic regression as usual\n",
    "np.random.seed(9001)\n",
    "df_filled = df_filled.dropna(how='all')\n",
    "msk = np.random.rand(len(df_filled)) < 0.75\n",
    "train_df = df_filled[msk]\n",
    "test_df = df_filled[~msk]\n",
    "#prepare train and tests\n",
    "xtrain = train_df.drop('DX', axis=1).values\n",
    "ytrain = train_df['DX'].values\n",
    "xtest = test_df.drop('DX', axis=1).values\n",
    "ytest = test_df['DX'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy of the fitted logistic regression is 0.9173553719008265.\n",
      "The classification accuracy of the all-zeros classifier is 0.42148760330578516.\n"
     ]
    }
   ],
   "source": [
    "#logistic regression fine-tuned via crossvalidation\n",
    "#using the L2 penalty\n",
    "model['log_lasso'] = LogisticRegressionCV(penalty='l2')\n",
    "model['log_lasso'].fit(xtrain,ytrain) \n",
    "print('The classification accuracy of the fitted logistic regression is {0}.'.format(class_ac(ytest, model['log_lasso'].predict(xtest))))\n",
    "yzeros = np.zeros(ytest.shape[0]) #all zeroes model\n",
    "print('The classification accuracy of the all-zeros classifier is {0}.'.format(class_ac(ytest, yzeros)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ADAS11', 'ADAS13', 'RAVLT_immediate', 'RAVLT_learning',\n",
      "       'RAVLT_perc_forgetting', 'FAQ', 'MOCA', 'EcogSPMem', 'EcogSPLang',\n",
      "       'EcogSPVisspat', 'EcogSPPlan', 'EcogSPOrgan', 'EcogSPDivatt',\n",
      "       'EcogSPTotal'],\n",
      "      dtype='object')\n",
      "Now working on ADAS11.\n",
      "The r2 score is 0.6875508934320097.\n",
      "Now working on ADAS13.\n",
      "The r2 score is 0.6842067261601028.\n",
      "Now working on RAVLT_immediate.\n",
      "The r2 score is 0.39267190524296536.\n",
      "Now working on RAVLT_learning.\n",
      "The r2 score is 0.20223000434719196.\n",
      "Now working on RAVLT_perc_forgetting.\n",
      "The r2 score is 0.26844855500150255.\n",
      "Now working on FAQ.\n",
      "The r2 score is 0.753149669397961.\n",
      "Now working on MOCA.\n",
      "The r2 score is 0.5849235641842113.\n",
      "Now working on EcogSPMem.\n",
      "The r2 score is 0.5323540409795313.\n",
      "Now working on EcogSPLang.\n",
      "The r2 score is 0.4874731056225644.\n",
      "Now working on EcogSPVisspat.\n",
      "The r2 score is 0.555398751695281.\n",
      "Now working on EcogSPPlan.\n",
      "The r2 score is 0.5508378516572242.\n",
      "Now working on EcogSPOrgan.\n",
      "The r2 score is 0.5173184554735832.\n",
      "Now working on EcogSPDivatt.\n",
      "The r2 score is 0.46628578294422185.\n",
      "Now working on EcogSPTotal.\n",
      "The r2 score is 0.6225011510433546.\n",
      "Index([], dtype='object')\n",
      "The classification accuracy of the fitted logistic regression is 0.9090909090909091.\n",
      "The classification accuracy of the all-zeros classifier is 0.42148760330578516.\n"
     ]
    }
   ],
   "source": [
    "#imputation through Ridge\n",
    "#adapted from lab7\n",
    "df_miss = pd.read_csv('FINAL_GENE_EXPRESSION.csv', index_col = 0)\n",
    "df_miss = df_miss[['CDRSB', 'ADAS11', 'ADAS13',\n",
    "       'MMSE', 'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_perc_forgetting',\n",
    "       'FAQ', 'MOCA', 'EcogSPMem', 'EcogSPLang', 'EcogSPVisspat', 'EcogSPPlan',\n",
    "       'EcogSPOrgan', 'EcogSPDivatt', 'EcogSPTotal', 'DX']]\n",
    "df_miss_cut = df_miss.dropna(how='all')\n",
    "df_filled = df_miss.copy()\n",
    "#using the intact data\n",
    "#build a model to use to impute\n",
    "#onto the dataset that has missing values\n",
    "#for each given predictors\n",
    "df_miss_cut = df_miss_cut.drop('DX', axis =1 )\n",
    "null_predictors = df_miss_cut.columns[df_miss_cut.isnull().any()] #get null predictors\n",
    "print(null_predictors)\n",
    "df_miss_cut.shape\n",
    "#impute\n",
    "for predictor in null_predictors:\n",
    "    print('Now working on {}.'.format(predictor))\n",
    "    #first the missing values\n",
    "    #from the dataset\n",
    "    null_miss = df_miss_cut[pd.DataFrame(data = df_miss_cut[predictor], index = df_miss_cut.index).isnull().any(axis=1)] #get all rows with missing values in that predict\n",
    "    #and the missing index from earlier\n",
    "    xmiss = null_miss.drop(null_predictors, axis=1)\n",
    "    miss_index = df_miss_cut[predictor][df_miss_cut[predictor].isnull()].index #index of missing rows\n",
    "    #now use the intact database\n",
    "    #to create the model\n",
    "    xnomiss = df_miss_cut.drop(null_predictors, axis=1)\n",
    "    ynomiss = pd.DataFrame(data = df_miss_cut[predictor], index = df_miss_cut[predictor].index) #note that ynomiss is looking at that particular predictor, not \"is_cancer\n",
    "    xnomiss = xnomiss.drop(miss_index)\n",
    "    ynomiss = ynomiss.drop(miss_index)\n",
    "    #create the model\n",
    "    model['Ridge'] = RidgeCV(alphas = alphas) #linear regression\n",
    "    model['Ridge'].fit(xnomiss, ynomiss) #fit\n",
    "    ynomiss_pred = model['Ridge'].predict(xnomiss) #predict on not-missing data\n",
    "    print('The r2 score is {}.'.format(r2_score(ynomiss.values, ynomiss_pred)))\n",
    "    ymiss_pred = model['Ridge'].predict(xmiss) #predict on missing data\n",
    "    #now include noise in the model\n",
    "    #using mean squared error\n",
    "    #calculated by the not-missing data\n",
    "    #so we know how generally accurate\n",
    "    #the model is and can thus\n",
    "    #add appropriate noise\n",
    "    ymiss_pred_noisy = ymiss_pred + np.random.normal(loc = 0, scale = np.sqrt(mean_squared_error(ynomiss.values, ynomiss_pred)), size = ymiss_pred.shape)\n",
    "    #put together the imputed values\n",
    "    miss_series = pd.Series(data = ymiss_pred.flatten(), index = miss_index)\n",
    "    df_filled[predictor] = df_filled[predictor].fillna(miss_series)\n",
    "null_predictors_check = df_filled.columns[df_filled.isnull().any()] #get null predictors\n",
    "print(null_predictors_check) #check to make sure this is empty!\n",
    "#now do the split and do the logistic regression as usual\n",
    "np.random.seed(9001)\n",
    "df_filled = df_filled.dropna(how='all')\n",
    "msk = np.random.rand(len(df_filled)) < 0.75\n",
    "train_df = df_filled[msk]\n",
    "test_df = df_filled[~msk]\n",
    "#prepare train and tests\n",
    "xtrain = train_df.drop('DX', axis=1).values\n",
    "ytrain = train_df['DX'].values\n",
    "xtest = test_df.drop('DX', axis=1).values\n",
    "ytest = test_df['DX'].values\n",
    "#logistic regression fine-tuned via crossvalidation\n",
    "#using the L2 penalty\n",
    "model['log_ridge'] = LogisticRegressionCV(penalty='l2')\n",
    "model['log_ridge'].fit(xtrain,ytrain) \n",
    "print('The classification accuracy of the fitted logistic regression is {0}.'.format(class_ac(ytest, model['log_ridge'].predict(xtest))))\n",
    "yzeros = np.zeros(ytest.shape[0]) #all zeroes model\n",
    "print('The classification accuracy of the all-zeros classifier is {0}.'.format(class_ac(ytest, yzeros)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ADAS11', 'ADAS13', 'RAVLT_immediate', 'RAVLT_learning',\n",
      "       'RAVLT_perc_forgetting', 'FAQ', 'MOCA', 'EcogSPMem', 'EcogSPLang',\n",
      "       'EcogSPVisspat', 'EcogSPPlan', 'EcogSPOrgan', 'EcogSPDivatt',\n",
      "       'EcogSPTotal'],\n",
      "      dtype='object')\n",
      "Now working on ADAS11.\n",
      "The r2 score is 0.6878303984629959.\n",
      "Now working on ADAS13.\n",
      "The r2 score is 0.684485626711936.\n",
      "Now working on RAVLT_immediate.\n",
      "The r2 score is 0.39289383486922924.\n",
      "Now working on RAVLT_learning.\n",
      "The r2 score is 0.20249048997663088.\n",
      "Now working on RAVLT_perc_forgetting.\n",
      "The r2 score is 0.2686892288562157.\n",
      "Now working on FAQ.\n",
      "The r2 score is 0.753179103890844.\n",
      "Now working on MOCA.\n",
      "The r2 score is 0.5852076887985204.\n",
      "Now working on EcogSPMem.\n",
      "The r2 score is 0.532377400974708.\n",
      "Now working on EcogSPLang.\n",
      "The r2 score is 0.4874871929067146.\n",
      "Now working on EcogSPVisspat.\n",
      "The r2 score is 0.5554284491898449.\n",
      "Now working on EcogSPPlan.\n",
      "The r2 score is 0.5508647799918345.\n",
      "Now working on EcogSPOrgan.\n",
      "The r2 score is 0.5173512568531835.\n",
      "Now working on EcogSPDivatt.\n",
      "The r2 score is 0.46630500577535494.\n",
      "Now working on EcogSPTotal.\n",
      "The r2 score is 0.6225275914495195.\n",
      "Index([], dtype='object')\n",
      "The classification accuracy of the fitted logistic regression is 0.9090909090909091.\n",
      "The classification accuracy of the all-zeros classifier is 0.42148760330578516.\n"
     ]
    }
   ],
   "source": [
    "#imputation through linear regression\n",
    "#adapted from lab7\n",
    "df_miss = pd.read_csv('FINAL_GENE_EXPRESSION.csv', index_col = 0)\n",
    "df_miss = df_miss[['CDRSB', 'ADAS11', 'ADAS13',\n",
    "       'MMSE', 'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_perc_forgetting',\n",
    "       'FAQ', 'MOCA', 'EcogSPMem', 'EcogSPLang', 'EcogSPVisspat', 'EcogSPPlan',\n",
    "       'EcogSPOrgan', 'EcogSPDivatt', 'EcogSPTotal', 'DX']]\n",
    "df_miss_cut = df_miss.dropna(how='all')\n",
    "df_filled = df_miss.copy()\n",
    "#using the intact data\n",
    "#build a model to use to impute\n",
    "#onto the dataset that has missing values\n",
    "#for each given predictors\n",
    "df_miss_cut = df_miss_cut.drop('DX', axis =1 )\n",
    "null_predictors = df_miss_cut.columns[df_miss_cut.isnull().any()] #get null predictors\n",
    "print(null_predictors)\n",
    "df_miss_cut.shape\n",
    "#impute\n",
    "for predictor in null_predictors:\n",
    "    print('Now working on {}.'.format(predictor))\n",
    "    #first the missing values\n",
    "    #from the dataset\n",
    "    null_miss = df_miss_cut[pd.DataFrame(data = df_miss_cut[predictor], index = df_miss_cut.index).isnull().any(axis=1)] #get all rows with missing values in that predict\n",
    "    #and the missing index from earlier\n",
    "    xmiss = null_miss.drop(null_predictors, axis=1)\n",
    "    miss_index = df_miss_cut[predictor][df_miss_cut[predictor].isnull()].index #index of missing rows\n",
    "    #now use the intact database\n",
    "    #to create the model\n",
    "    xnomiss = df_miss_cut.drop(null_predictors, axis=1)\n",
    "    ynomiss = pd.DataFrame(data = df_miss_cut[predictor], index = df_miss_cut[predictor].index) #note that ynomiss is looking at that particular predictor, not \"is_cancer\n",
    "    xnomiss = xnomiss.drop(miss_index)\n",
    "    ynomiss = ynomiss.drop(miss_index)\n",
    "    #create the model\n",
    "    model['Linear'] = LinearRegression() #linear regression\n",
    "    model['Linear'].fit(xnomiss, ynomiss) #fit\n",
    "    ynomiss_pred = model['Linear'].predict(xnomiss) #predict on not-missing data\n",
    "    print('The r2 score is {}.'.format(r2_score(ynomiss.values, ynomiss_pred)))\n",
    "    ymiss_pred = model['Linear'].predict(xmiss) #predict on missing data\n",
    "    #now include noise in the model\n",
    "    #using mean squared error\n",
    "    #calculated by the not-missing data\n",
    "    #so we know how generally accurate\n",
    "    #the model is and can thus\n",
    "    #add appropriate noise\n",
    "    ymiss_pred_noisy = ymiss_pred + np.random.normal(loc = 0, scale = np.sqrt(mean_squared_error(ynomiss.values, ynomiss_pred)), size = ymiss_pred.shape)\n",
    "    #put together the imputed values\n",
    "    miss_series = pd.Series(data = ymiss_pred.flatten(), index = miss_index)\n",
    "    df_filled[predictor] = df_filled[predictor].fillna(miss_series)\n",
    "null_predictors_check = df_filled.columns[df_filled.isnull().any()] #get null predictors\n",
    "print(null_predictors_check) #check to make sure this is empty!\n",
    "#now do the split and do the logistic regression as usual\n",
    "np.random.seed(9001)\n",
    "df_filled = df_filled.dropna(how='all')\n",
    "msk = np.random.rand(len(df_filled)) < 0.75\n",
    "train_df = df_filled[msk]\n",
    "test_df = df_filled[~msk]\n",
    "#prepare train and tests\n",
    "xtrain = train_df.drop('DX', axis=1).values\n",
    "ytrain = train_df['DX'].values\n",
    "xtest = test_df.drop('DX', axis=1).values\n",
    "ytest = test_df['DX'].values\n",
    "#logistic regression fine-tuned via crossvalidation\n",
    "#using the L2 penalty\n",
    "model['log_lin'] = LogisticRegressionCV(penalty='l2')\n",
    "model['log_lin'].fit(xtrain,ytrain) \n",
    "print('The classification accuracy of the fitted logistic regression is {0}.'.format(class_ac(ytest, model['log_lin'].predict(xtest))))\n",
    "yzeros = np.zeros(ytest.shape[0]) #all zeroes model\n",
    "print('The classification accuracy of the all-zeros classifier is {0}.'.format(class_ac(ytest, yzeros)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ADAS11', 'ADAS13', 'RAVLT_immediate', 'RAVLT_learning',\n",
      "       'RAVLT_perc_forgetting', 'FAQ', 'MOCA', 'EcogSPMem', 'EcogSPLang',\n",
      "       'EcogSPVisspat', 'EcogSPPlan', 'EcogSPOrgan', 'EcogSPDivatt',\n",
      "       'EcogSPTotal'],\n",
      "      dtype='object')\n",
      "Now working on ADAS11.\n",
      "The r2 score is 0.7154929492672664.\n",
      "Now working on ADAS13.\n",
      "The r2 score is 0.7171846220305957.\n",
      "Now working on RAVLT_immediate.\n",
      "The r2 score is 0.44372227239655027.\n",
      "Now working on RAVLT_learning.\n",
      "The r2 score is 0.23365963126397093.\n",
      "Now working on RAVLT_perc_forgetting.\n",
      "The r2 score is 0.3204344253774243.\n",
      "Now working on FAQ.\n",
      "The r2 score is 0.7621861374078318.\n",
      "Now working on MOCA.\n",
      "The r2 score is 0.6008333153764035.\n",
      "Now working on EcogSPMem.\n",
      "The r2 score is 0.6466117970433768.\n",
      "Now working on EcogSPLang.\n",
      "The r2 score is 0.5293601837756068.\n",
      "Now working on EcogSPVisspat.\n",
      "The r2 score is 0.5710668891738866.\n",
      "Now working on EcogSPPlan.\n",
      "The r2 score is 0.5801879166443826.\n",
      "Now working on EcogSPOrgan.\n",
      "The r2 score is 0.5526735381250583.\n",
      "Now working on EcogSPDivatt.\n",
      "The r2 score is 0.5231586599060172.\n",
      "Now working on EcogSPTotal.\n",
      "The r2 score is 0.683518526659628.\n",
      "Index([], dtype='object')\n",
      "The classification accuracy of the fitted logistic regression is 0.9338842975206612.\n",
      "The classification accuracy of the all-zeros classifier is 0.42148760330578516.\n"
     ]
    }
   ],
   "source": [
    "#imputation through linear regression with polynomial features\n",
    "\n",
    "#include polynomial terms\n",
    "quad_terms = PolynomialFeatures(degree = 2) #include quadratic terms\n",
    "\n",
    "#adapted from lab7\n",
    "df_miss = pd.read_csv('FINAL_GENE_EXPRESSION.csv', index_col = 0)\n",
    "df_miss = df_miss[['CDRSB', 'ADAS11', 'ADAS13',\n",
    "       'MMSE', 'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_perc_forgetting',\n",
    "       'FAQ', 'MOCA', 'EcogSPMem', 'EcogSPLang', 'EcogSPVisspat', 'EcogSPPlan',\n",
    "       'EcogSPOrgan', 'EcogSPDivatt', 'EcogSPTotal', 'DX']]\n",
    "df_miss_cut = df_miss.dropna(how='all')\n",
    "df_filled = df_miss.copy()\n",
    "#using the intact data\n",
    "#build a model to use to impute\n",
    "#onto the dataset that has missing values\n",
    "#for each given predictors\n",
    "df_miss_cut = df_miss_cut.drop('DX', axis =1 )\n",
    "null_predictors = df_miss_cut.columns[df_miss_cut.isnull().any()] #get null predictors\n",
    "print(null_predictors)\n",
    "df_miss_cut.shape\n",
    "#impute\n",
    "for predictor in null_predictors:\n",
    "    print('Now working on {}.'.format(predictor))\n",
    "    #first the missing values\n",
    "    #from the dataset\n",
    "    null_miss = df_miss_cut[pd.DataFrame(data = df_miss_cut[predictor], index = df_miss_cut.index).isnull().any(axis=1)] #get all rows with missing values in that predict\n",
    "    #and the missing index from earlier\n",
    "    xmiss = null_miss.drop(null_predictors, axis=1)\n",
    "    xmiss = quad_terms.fit_transform(xmiss)\n",
    "    miss_index = df_miss_cut[predictor][df_miss_cut[predictor].isnull()].index #index of missing rows\n",
    "    #now use the intact database\n",
    "    #to create the model\n",
    "    xnomiss = df_miss_cut.drop(null_predictors, axis=1)\n",
    "    ynomiss = pd.DataFrame(data = df_miss_cut[predictor], index = df_miss_cut[predictor].index) #note that ynomiss is looking at that particular predictor, not \"is_cancer\n",
    "    xnomiss = xnomiss.drop(miss_index)\n",
    "    ynomiss = ynomiss.drop(miss_index)\n",
    "    xnomiss = quad_terms.fit_transform(xnomiss)\n",
    "    #create the model\n",
    "    model['Poly'] = LinearRegression() #linear regression\n",
    "    model['Poly'].fit(xnomiss, ynomiss) #fit\n",
    "    ynomiss_pred = model['Poly'].predict(xnomiss) #predict on not-missing data\n",
    "    print('The r2 score is {}.'.format(r2_score(ynomiss.values, ynomiss_pred)))\n",
    "    ymiss_pred = model['Poly'].predict(xmiss) #predict on missing data\n",
    "    #now include noise in the model\n",
    "    #using mean squared error\n",
    "    #calculated by the not-missing data\n",
    "    #so we know how generally accurate\n",
    "    #the model is and can thus\n",
    "    #add appropriate noise\n",
    "    ymiss_pred_noisy = ymiss_pred + np.random.normal(loc = 0, scale = np.sqrt(mean_squared_error(ynomiss.values, ynomiss_pred)), size = ymiss_pred.shape)\n",
    "    #put together the imputed values\n",
    "    miss_series = pd.Series(data = ymiss_pred.flatten(), index = miss_index)\n",
    "    df_filled[predictor] = df_filled[predictor].fillna(miss_series)\n",
    "null_predictors_check = df_filled.columns[df_filled.isnull().any()] #get null predictors\n",
    "print(null_predictors_check) #check to make sure this is empty!\n",
    "#now do the split and do the logistic regression as usual\n",
    "np.random.seed(9001)\n",
    "df_filled = df_filled.dropna(how='all')\n",
    "msk = np.random.rand(len(df_filled)) < 0.75\n",
    "train_df = df_filled[msk]\n",
    "test_df = df_filled[~msk]\n",
    "#prepare train and tests\n",
    "xtrain = train_df.drop('DX', axis=1).values\n",
    "ytrain = train_df['DX'].values\n",
    "xtest = test_df.drop('DX', axis=1).values\n",
    "ytest = test_df['DX'].values\n",
    "#logistic regression fine-tuned via crossvalidation\n",
    "#using the L2 penalty\n",
    "model['log_poly'] = LogisticRegressionCV(penalty='l2')\n",
    "model['log_poly'].fit(xtrain,ytrain) \n",
    "print('The classification accuracy of the fitted logistic regression is {0}.'.format(class_ac(ytest, model['log_poly'].predict(xtest))))\n",
    "yzeros3 = np.zeros(ytest.shape[0]) #all zeroes model\n",
    "print('The classification accuracy of the all-zeros classifier is {0}.'.format(class_ac(ytest, yzeros)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop poorly imputed (r^2 < .5) columns\n",
    "df_filled = df_filled.drop(['RAVLT_immediate', 'RAVLT_learning', 'RAVLT_perc_forgetting'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy of the fitted logistic regression is 0.9338842975206612.\n",
      "The classification accuracy of the all-zeros classifier is 0.42148760330578516.\n"
     ]
    }
   ],
   "source": [
    "#now do the split and do the logistic regression for final imputed model\n",
    "np.random.seed(9001)\n",
    "df_filled = df_filled.dropna(how='all')\n",
    "msk = np.random.rand(len(df_filled)) < 0.75\n",
    "train_df = df_filled[msk]\n",
    "test_df = df_filled[~msk]\n",
    "#prepare train and tests\n",
    "xtrain = train_df.drop('DX', axis=1).values\n",
    "ytrain = train_df['DX'].values\n",
    "xtest = test_df.drop('DX', axis=1).values\n",
    "ytest = test_df['DX'].values\n",
    "model['final'] = LogisticRegressionCV(penalty='l2')\n",
    "model['final'].fit(xtrain,ytrain) \n",
    "print('The classification accuracy of the fitted logistic regression is {0}.'.format(class_ac(ytest, model['final'].predict(xtest))))\n",
    "yzeros = np.zeros(ytest.shape[0]) #all zeroes model\n",
    "print('The classification accuracy of the all-zeros classifier is {0}.'.format(class_ac(ytest, yzeros)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop imputed columns\n",
    "df_full = df_full.drop(['RAVLT_immediate', 'RAVLT_learning', 'RAVLT_perc_forgetting', 'CDRSB', 'ADAS11', 'ADAS13',\n",
    "       'MMSE', 'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_perc_forgetting',\n",
    "       'FAQ', 'MOCA', 'EcogSPMem', 'EcogSPLang', 'EcogSPVisspat', 'EcogSPPlan',\n",
    "       'EcogSPOrgan', 'EcogSPDivatt', 'EcogSPTotal', 'DX'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add imputed columns\n",
    "df_final = df_filled.join(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export csv\n",
    "df_final.to_csv('Post-Imputation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for any null\n",
    "df_final.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
